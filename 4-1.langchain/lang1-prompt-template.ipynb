{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (0.3.21)\n",
      "Requirement already satisfied: openai in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (1.75.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: pypdf in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (5.4.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain) (0.3.49)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain) (0.3.19)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain openai faiss-cpu tiktoken pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17912,
     "status": "ok",
     "timestamp": 1745736151796,
     "user": {
      "displayName": "Taewook Kang",
      "userId": "11578752810222612195"
     },
     "user_tz": -540
    },
    "id": "n-zGakAZ-X9G"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "key = userdata.get('openai-api')\n",
    "\n",
    "# from huggingface_hub import login\n",
    "# login(token=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1551,
     "status": "ok",
     "timestamp": 1745736166853,
     "user": {
      "displayName": "Taewook Kang",
      "userId": "11578752810222612195"
     },
     "user_tz": -540
    },
    "id": "T_WVHfbF7Tab",
    "outputId": "eda3ef2b-5b93-4c90-94da-44b2277db5f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the question based on the context below. If the\n",
      "question cannot be answered using the information provided answer\n",
      "with \"I don't know\".\n",
      "\n",
      "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
      "Their superior performance over smaller models has made them incredibly\n",
      "useful for developers building NLP enabled applications. These models\n",
      "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
      "using the `openai` library, and via Cohere using the `cohere` library.\n",
      "\n",
      "Question: What is the capital of Norway?\n",
      "\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "output = prompt_template.format(query=\"What is the capital of Norway?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0GYrNlCz--a8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO6oR6/kvTEuBzyEDI1SwbZ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv_lmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

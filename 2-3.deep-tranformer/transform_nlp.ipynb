{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaTU23Ucufii",
        "outputId": "a6b75673-5b64-4e8f-8b55-f9318c07b811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.51.3 in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: portalocker==3.1.1 in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (2025.1.31)\n",
            "Requirement already satisfied: datasets==3.5.0 in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets==3.5.0) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets==3.5.0) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.5.0) (1.17.0)\n",
            "Requirement already satisfied: torchtext==0.15.1 in /usr/local/lib/python3.11/dist-packages (0.15.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (2.32.3)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (2.0.2)\n",
            "Requirement already satisfied: torchdata==0.6.0 in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (0.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.0->torchtext==0.15.1) (2.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext==0.15.1) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext==0.15.1) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext==0.15.1) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext==0.15.1) (18.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.1) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.1) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.0->torchtext==0.15.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.0->torchtext==0.15.1) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.51.3 portalocker==3.1.1\n",
        "!pip install datasets==3.5.0\n",
        "!pip install torchtext==0.15.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "key = userdata.get('hf-api')\n",
        "\n",
        "from huggingface_hub import login\n",
        "login(token=key)"
      ],
      "metadata": {
        "id": "v-5dayQXujWD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math, matplotlib.pyplot as plt, os, numpy\n",
        "import torch, torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import multi30k, Multi30k\n",
        "from typing import Iterable, List\n",
        "from torch import Tensor\n",
        "from torch.nn import Transformer # https://github.com/pytorch/pytorch/blob/main/torch/nn/modules/transformer.py, https://github.com/pytorch/pytorch/blob/main/torch/nn/modules/activation.py\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from timeit import default_timer as timer"
      ],
      "metadata": {
        "id": "ZjSimtRvujfF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {DEVICE}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHjSQku2ujkY",
        "outputId": "615e575f-6add-4c0d-a01f-3ec1568a7941"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_LANGUAGE = 'de'\n",
        "TGT_LANGUAGE = 'en'\n",
        "token_transform = {}\n",
        "vocab_transform = {}\n",
        "text_transform = {}\n",
        "\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "\n",
        "EMB_SIZE = 512\n",
        "NHEAD = 8\n",
        "FFN_HID_DIM = 512\n",
        "BATCH_SIZE = 128\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3\n",
        "NUM_EPOCHS = 2 # 5 18 BEST # 50"
      ],
      "metadata": {
        "id": "u_gIldaRujmo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# current date and time\n",
        "current_date_time_string = str(datetime.now().strftime(\"%Y%m%d_%H%M\"))\n",
        "\n",
        "# We need to modify the URLs for the dataset since the links to the original dataset are broken\n",
        "# Refer to https://github.com/pytorch/text/issues/1756#issuecomment-1163664163 for more info\n",
        "multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
        "multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n"
      ],
      "metadata": {
        "id": "Y1PNUQHvzJ9F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download de_core_news_sm\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUCr6YZ60CFR",
        "outputId": "42ee1bf8-0cf8-493f-982d-1ee6e2ceaecb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting de-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.8.0/de_core_news_sm-3.8.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Place-holders\n",
        "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
        "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "\n",
        "print(token_transform[SRC_LANGUAGE](\"Eine Gruppe von Menschen steht vor einem Iglu .\"))\n",
        "print(token_transform[TGT_LANGUAGE](\"A group of people are standing in front of an igloo .\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FML6bSMpzJ_0",
        "outputId": "4ea53e3b-0f91-47ee-f33d-e33f9cd09402"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Eine', 'Gruppe', 'von', 'Menschen', 'steht', 'vor', 'einem', 'Iglu', '.']\n",
            "['A', 'group', 'of', 'people', 'are', 'standing', 'in', 'front', 'of', 'an', 'igloo', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to yield list of tokens\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "\tlanguage_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "\tfor data_sample in data_iter:\n",
        "\t\tyield token_transform[language](data_sample[language_index[language]])\n"
      ],
      "metadata": {
        "id": "fo78lprKzKJh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define special symbols and indices. Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "for i, (src, tgt) in enumerate(train_iter):\n",
        "\tif i >= 5:\n",
        "\t\tbreak\n",
        "\tprint(f\"Source[{i}]: {src}\")\n",
        "\tprint(f\"Target[{i}]: {tgt}\")\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "\t# Create torchtext's Vocab object\n",
        "\tvocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tmin_freq=1,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tspecials=special_symbols,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tspecial_first=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qeEQn6FzKCC",
        "outputId": "2aaa81e5-9b52-4488-e9ce-190ddf1dbdf7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source[0]: Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\n",
            "Target[0]: Two young, White males are outside near many bushes.\n",
            "Source[1]: Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.\n",
            "Target[1]: Several men in hard hats are operating a giant pulley system.\n",
            "Source[2]: Ein kleines Mädchen klettert in ein Spielhaus aus Holz.\n",
            "Target[2]: A little girl climbing into a wooden playhouse.\n",
            "Source[3]: Ein Mann in einem blauen Hemd steht auf einer Leiter und putzt ein Fenster.\n",
            "Target[3]: A man in a blue shirt is standing on a ladder cleaning a window.\n",
            "Source[4]: Zwei Männer stehen am Herd und bereiten Essen zu.\n",
            "Target[4]: Two men are at the stove preparing food.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/datapipes/iter/combining.py:297: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set ``UNK_IDX`` as the default index. This index is returned when the token is not found.\n",
        "# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "\tvocab_transform[ln].set_default_index(UNK_IDX)\n",
        "torch.manual_seed(0)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LSbjuQYzKEg",
        "outputId": "b146d0d9-6b59-47e2-ea5d-1527adcaeea6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a410c320e30>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to collate data samples into batch tensors\n",
        "def collate_fn(batch):\n",
        "\tglobal text_transform\n",
        "\n",
        "\tsrc_batch, tgt_batch = [], []\n",
        "\tfor src_sample, tgt_sample in batch:\n",
        "\t\tsrc_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
        "\t\ttgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "\tsrc_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "\ttgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "\treturn src_batch, tgt_batch\n"
      ],
      "metadata": {
        "id": "hvtR0zc5zhSY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "\tdef func(txt_input):\n",
        "\t\tfor transform in transforms:\n",
        "\t\t\ttxt_input = transform(txt_input)\n",
        "\t\treturn txt_input\n",
        "\treturn func\n"
      ],
      "metadata": {
        "id": "9U2sV1zJzhNY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids: List[int]):\n",
        "\treturn torch.cat((torch.tensor([BOS_IDX]),\n",
        "\t\t\t\t\ttorch.tensor(token_ids),\n",
        "\t\t\t\t\ttorch.tensor([EOS_IDX])))\n"
      ],
      "metadata": {
        "id": "3rIV1DBKzhP0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
        "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
        "\n",
        "train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "\ttext_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "\t\t\t\t\t\t\t\t\t\t\tvocab_transform[ln], #Numericalization\n",
        "\t\t\t\t\t\t\t\t\t\t\ttensor_transform) # Add BOS/EOS and create tensor\n"
      ],
      "metadata": {
        "id": "kHiFOlXPzKHC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
        "class PositionalEncoding(nn.Module):\n",
        "\tdef __init__(self,\n",
        "\t\t\t\temb_size: int,\n",
        "\t\t\t\tdropout: float,\n",
        "\t\t\t\tmaxlen: int = 5000):\n",
        "\t\tsuper(PositionalEncoding, self).__init__()\n",
        "\t\tden = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "\t\tpos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "\t\tpos_embedding = torch.zeros((maxlen, emb_size))\n",
        "\t\tpos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "\t\tpos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "\t\tpos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "\t\tself.dropout = nn.Dropout(dropout)\n",
        "\t\tself.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "\tdef forward(self, token_embedding: Tensor):\n",
        "\t\treturn self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n"
      ],
      "metadata": {
        "id": "bOmFMX4vzKLx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
        "class TokenEmbedding(nn.Module):\n",
        "\tdef __init__(self, vocab_size: int, emb_size):\n",
        "\t\tsuper(TokenEmbedding, self).__init__()\n",
        "\t\tself.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "\t\tself.emb_size = emb_size\n",
        "\n",
        "\tdef forward(self, tokens: Tensor):\n",
        "\t\treturn self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n"
      ],
      "metadata": {
        "id": "6p00MT_ezYu8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seq2Seq Network\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "\tdef __init__(self,\n",
        "\t\t\t\tnum_encoder_layers: int,\n",
        "\t\t\t\tnum_decoder_layers: int,\n",
        "\t\t\t\temb_size: int,\n",
        "\t\t\t\tnhead: int,\n",
        "\t\t\t\tsrc_vocab_size: int,\n",
        "\t\t\t\ttgt_vocab_size: int,\n",
        "\t\t\t\tdim_feedforward: int = 512,\n",
        "\t\t\t\tdropout: float = 0.1):\n",
        "\t\tsuper(Seq2SeqTransformer, self).__init__()\n",
        "\t\tself.transformer = Transformer(d_model=emb_size,\n",
        "\t\t\t\t\t\t\t\t\tnhead=nhead,\n",
        "\t\t\t\t\t\t\t\t\tnum_encoder_layers=num_encoder_layers,\n",
        "\t\t\t\t\t\t\t\t\tnum_decoder_layers=num_decoder_layers,\n",
        "\t\t\t\t\t\t\t\t\tdim_feedforward=dim_feedforward,\n",
        "\t\t\t\t\t\t\t\t\tdropout=dropout)\n",
        "\t\tself.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "\t\tself.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "\t\tself.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "\t\tself.positional_encoding = PositionalEncoding(\n",
        "\t\t\temb_size, dropout=dropout)\n",
        "\n",
        "\tdef forward(self,\n",
        "\t\t\t\tsrc: Tensor,\n",
        "\t\t\t\ttrg: Tensor,\n",
        "\t\t\t\tsrc_mask: Tensor,\n",
        "\t\t\t\ttgt_mask: Tensor,\n",
        "\t\t\t\tsrc_padding_mask: Tensor,\n",
        "\t\t\t\ttgt_padding_mask: Tensor,\n",
        "\t\t\t\tmemory_key_padding_mask: Tensor):\n",
        "\t\tsrc_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "\t\ttgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "\t\touts = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
        "\t\t\t\t\t\t\t\tsrc_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
        "\t\treturn self.generator(outs)\n",
        "\n",
        "\tdef encode(self, src: Tensor, src_mask: Tensor):\n",
        "\t\treturn self.transformer.encoder(self.positional_encoding(\n",
        "\t\t\t\t\t\t\tself.src_tok_emb(src)), src_mask)\n",
        "\n",
        "\tdef decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "\t\treturn self.transformer.decoder(self.positional_encoding(\n",
        "\t\t\t\t\t\tself.tgt_tok_emb(tgt)), memory,\n",
        "\t\t\t\t\t\ttgt_mask)\n"
      ],
      "metadata": {
        "id": "wJeRMIC-zYxU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_square_subsequent_mask(sz): # create diagonal matrix\n",
        "\tmask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
        "\tmask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "\treturn mask\n",
        "\n"
      ],
      "metadata": {
        "id": "qfzsTzFCzYzw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mask(src, tgt):\n",
        "\tsrc_seq_len = src.shape[0]\n",
        "\ttgt_seq_len = tgt.shape[0]\n",
        "\n",
        "\ttgt_mask = generate_square_subsequent_mask(tgt_seq_len).to(DEVICE)\n",
        "\tsrc_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool) # don't train future token\n",
        "\n",
        "\tsrc_padding_mask = (src == PAD_IDX).transpose(0, 1) # padding mask\n",
        "\ttgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1) # padding mask\n",
        "\treturn src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n"
      ],
      "metadata": {
        "id": "gVR4cv4uzKis"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(val_dataloader, model, loss_fn):\n",
        "\tmodel.eval()\n",
        "\tlosses = 0\n",
        "\n",
        "\tfor src, tgt in tqdm(val_dataloader):\n",
        "\t\tsrc = src.to(DEVICE)\n",
        "\t\ttgt = tgt.to(DEVICE)\n",
        "\n",
        "\t\ttgt_input = tgt[:-1, :]\n",
        "\t\tsrc_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "\t\tlogits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "\t\ttgt_out = tgt[1:, :]\n",
        "\t\tloss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "\t\tlosses += loss.item()\n",
        "\n",
        "\treturn losses / len(list(val_dataloader))\n"
      ],
      "metadata": {
        "id": "7BcNKhD-zhUo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to generate output sequence using greedy algorithm\n",
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "\tsrc = src.to(DEVICE)\n",
        "\tsrc_mask = src_mask.to(DEVICE)\n",
        "\n",
        "\tmemory = model.encode(src, src_mask)\n",
        "\tys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "\tfor i in range(max_len-1):\n",
        "\t\tmemory = memory.to(DEVICE)\n",
        "\t\ttgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "\t\t\t\t\t.type(torch.bool)).to(DEVICE)\n",
        "\t\tout = model.decode(ys, memory, tgt_mask)\n",
        "\t\tout = out.transpose(0, 1)\n",
        "\t\tprob = model.generator(out[:, -1])\n",
        "\t\t_, next_word = torch.max(prob, dim=1)\n",
        "\t\tnext_word = next_word.item()\n",
        "\n",
        "\t\tys = torch.cat([ys,\n",
        "\t\t\t\t\t\ttorch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "\t\tif next_word == EOS_IDX:\n",
        "\t\t\tbreak\n",
        "\treturn ys\n"
      ],
      "metadata": {
        "id": "QXrwZoPdzmcg"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# actual function to translate input sentence into target language\n",
        "def translate(model: torch.nn.Module, src_sentence: str):\n",
        "\tglobal text_transform\n",
        "\n",
        "\tmodel.eval()\n",
        "\tsrc = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1).to(DEVICE)\n",
        "\tnum_tokens = src.shape[0]\n",
        "\tsrc_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool).to(DEVICE)\n",
        "\ttgt_tokens = greedy_decode(\n",
        "\t\tmodel,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "\treturn \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n"
      ],
      "metadata": {
        "id": "tou1B2uYzmgU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(train_dataloader, BATCH_SIZE, model, optimizer, loss_fn):\n",
        "\tmodel.train()\n",
        "\tlosses = 0\n",
        "\n",
        "\tfor index, (src, tgt) in tqdm(enumerate(train_dataloader)):\n",
        "\t\tsrc = src.to(DEVICE)  # (29,128)\n",
        "\t\ttgt = tgt.to(DEVICE)  # (36,128)\n",
        "\t\ttgt_input = tgt[:-1, :]\n",
        "\t\tsrc_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "\t\tlogits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\t\toptimizer.zero_grad()\n",
        "\n",
        "\t\ttgt_out = tgt[1:, :] # tgt(sequence, batch)=(36,128). shift sequence left side=(35,128)\n",
        "\t\tloss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1)) # (35*128,voca token prob)=(4480, 10837), tgt_out(4480). loss = max_index of logits's each row is predicted token - tgt_out's each element\n",
        "\t\tloss.backward()\n",
        "\n",
        "\t\toptimizer.step()\n",
        "\t\tlosses += loss.item()\n",
        "\n",
        "\treturn losses / len(list(train_dataloader))\n"
      ],
      "metadata": {
        "id": "UewmpzkEzmjF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model():\n",
        "\tglobal token_tranform, vocab_transform\n",
        "\tglobal PAD_IDX, BOS_IDX, EOS_IDX, UNK_IDX\n",
        "\tglobal SRC_VOCAB_SIZE, TGT_VOCAB_SIZE\n",
        "\tglobal NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, NHEAD, FFN_HID_DIM\n",
        "\n",
        "\ttransformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
        "\t\t\t\t\t\t\t\t\tNHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "\tfor p in transformer.parameters():\n",
        "\t\tif p.dim() > 1:\n",
        "\t\t\tnn.init.xavier_uniform_(p)\n",
        "\n",
        "\ttransformer = transformer.to(DEVICE)\n",
        "\tloss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\toptimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "\t# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n",
        "\tglobal text_transform\n",
        "\n",
        "\t# current path of this module\n",
        "\tmodule_path = \".\" # os.path.dirname(os.path.abspath(__file__))\n",
        "\twriter = SummaryWriter(log_dir=os.path.join(module_path, \"logs\"))\n",
        "\ttrain_losses = []\n",
        "\tval_losses = []\n",
        "\tfor epoch in range(1, NUM_EPOCHS+1):\n",
        "\t\tstart_time = timer()\n",
        "\t\ttrain_loss = train_epoch(train_dataloader, BATCH_SIZE, transformer, optimizer, loss_fn)\n",
        "\t\ttrain_losses.append(train_loss)\n",
        "\t\tend_time = timer()\n",
        "\t\tval_loss = evaluate(val_dataloader, transformer, loss_fn)\n",
        "\t\tval_losses.append(val_loss)\n",
        "\t\twriter.add_scalar(\"Train Loss\", train_loss, epoch)\n",
        "\t\twriter.add_scalar(\"Validation Loss\", val_loss, epoch)\n",
        "\t\tprint((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
        "\n",
        "\twriter.close()\n",
        "\n",
        "\tmodel_file = module_path + '/' + current_date_time_string + '_transformer_model.pth'\n",
        "\ttorch.save(transformer.state_dict(), model_file)\n",
        "\tprint(translate(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\"))\n",
        "\n",
        "\t# plot\n",
        "\tplt.xlabel(\"Epoch\")\n",
        "\tplt.ylabel(\"Loss\")\n",
        "\tplt.legend()\n",
        "\tplt.plot(range(1, NUM_EPOCHS+1), train_losses, label=\"Train Loss\")\n",
        "\tplt.show()\n",
        "\n",
        "\tplt.legend()\n",
        "\tplt.plot(range(1, NUM_EPOCHS+1), val_losses, label=\"Validation Loss\")\n",
        "\tplt.show()\n",
        "\n",
        "\treturn model_file\n"
      ],
      "metadata": {
        "id": "Sz4hSk8UzhXA"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model_file):\n",
        "\tglobal token_tranform, vocab_transform, text_transform\n",
        "\tglobal PAD_IDX, BOS_IDX, EOS_IDX, UNK_IDX\n",
        "\tglobal SRC_VOCAB_SIZE, TGT_VOCAB_SIZE\n",
        "\tglobal NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, NHEAD, FFN_HID_DIM\n",
        "\n",
        "\ttransformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
        "\t\t\t\t\t\t\t\t\tNHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "\t# load transformer model\n",
        "\tpth = torch.load(model_file)\n",
        "\ttransformer.load_state_dict(pth)\n",
        "\ttransformer.eval()\n",
        "\ttransformer = transformer.to(DEVICE)\n",
        "\n",
        "\tprint(translate(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\"))\n",
        "\n",
        "\tval_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "\tfor i, (src, tgt) in enumerate(val_iter):\n",
        "\t\tif i >= 5:\n",
        "\t\t\tbreak\n",
        "\t\tprint(f\"Source[{i}]: {src}\")\n",
        "\t\tprint(f\"Target[{i}]: {tgt}\")\n",
        "\n",
        "\t\toutput = translate(transformer, src)\n",
        "\t\tprint(f\"Predicted[{i}]: {output}\")\n",
        "\n",
        "\tinput()\n"
      ],
      "metadata": {
        "id": "kczpPaR_zhZ2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fname = train_model()\n",
        "test_model(fname)\n",
        "# test_model('./20250420_0945_transformer_model.pth')\n",
        "test_model('./20250419_2309_transformer_model.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_RT6AckztyV",
        "outputId": "1d13c2b5-e586-473f-9a3d-46275fef041e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched src_key_padding_mask and src_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "186it [00:35,  4.97it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V8s_xqsqzt3M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}